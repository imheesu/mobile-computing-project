{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing torchprofile...\n",
      "Requirement already satisfied: torchprofile in c:\\users\\heesu\\anaconda3\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchprofile) (1.24.3)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchprofile) (2.1.1)\n",
      "Requirement already satisfied: torchvision>=0.4 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchprofile) (0.16.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (2023.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchvision>=0.4->torchprofile) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchvision>=0.4->torchprofile) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.4->torchprofile) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\n",
      "All required packages have been successfully installed!\n"
     ]
    }
   ],
   "source": [
    "print('Installing torchprofile...')\n",
    "!pip install torchprofile\n",
    "print('All required packages have been successfully installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from collections import OrderedDict, defaultdict\n",
    "from typing import Union, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56379, 90, 6)\n",
      "(56379, 1)\n",
      "(37530, 90, 6)\n",
      "(37530, 1)\n"
     ]
    }
   ],
   "source": [
    "annotation_train_path = './dataset/annotation_train.csv'\n",
    "dataset_train_path = './dataset/data_train.npy'\n",
    "annotation_test_path = './dataset/annotation_test.csv'\n",
    "dataset_test_path = './dataset/data_test.npy'\n",
    "\n",
    "class RunningDataset(Dataset):\n",
    "    def __init__(self,annotation_path, dataset_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.labels = pd.read_csv(annotation_path, header=None)\n",
    "        self.data = np.load(dataset_path)\n",
    "\n",
    "        print (self.data.shape)\n",
    "        print (self.labels.shape)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        sample = torch.tensor(sample, dtype=torch.float32)\n",
    "        label = self.labels.iloc[idx,0]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample, label\n",
    "\n",
    "train_dataset = RunningDataset(annotation_train_path, dataset_train_path)\n",
    "test_dataset = RunningDataset(annotation_test_path, dataset_test_path)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=100,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=100,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (gru1): GRU(6, 32, batch_first=True)\n",
      "  (relu1): ReLU()\n",
      "  (gru2): GRU(32, 32, batch_first=True)\n",
      "  (relu2): ReLU()\n",
      "  (backbone): Sequential(\n",
      "    (conv0): Conv1d(32, 64, kernel_size=(2,), stride=(2,))\n",
      "    (relu0): ReLU()\n",
      "    (pool0): MaxPool1d(kernel_size=4, stride=4, padding=1, dilation=1, ceil_mode=False)\n",
      "    (conv1): Conv1d(64, 128, kernel_size=(2,), stride=(1,))\n",
      "    (relu1): ReLU()\n",
      "    (adaptivePoll0): AdaptiveAvgPool1d(output_size=1)\n",
      "    (bn0): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=128, out_features=4, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view((-1,) + self.shape)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "\n",
    "    layers = []\n",
    "    counts = defaultdict(int)\n",
    "    self.seq_len = 90\n",
    "\n",
    "    def add(name: str, layer: nn.Module) -> None:\n",
    "      layers.append((f\"{name}{counts[name]}\", layer))\n",
    "      counts[name] += 1\n",
    "\n",
    "    self.gru1 = nn.GRU(input_size=6, hidden_size=32, batch_first=True)\n",
    "    self.relu1 = nn.ReLU()\n",
    "    self.gru2 = nn.GRU(input_size=32, hidden_size=32, batch_first=True)\n",
    "    self.relu2 = nn.ReLU()\n",
    "    add(\"conv\", nn.Conv1d(32, 64, 2, stride=2))\n",
    "    add(\"relu\", nn.ReLU())\n",
    "    add(\"pool\", nn.MaxPool1d(4, padding=1))\n",
    "    add(\"conv\", nn.Conv1d(64, 128, 2, stride=1))\n",
    "    add(\"relu\", nn.ReLU())\n",
    "    add(\"adaptivePoll\",nn.AdaptiveAvgPool1d(1))\n",
    "    add(\"bn\", nn.BatchNorm1d(128, eps=1e-06))\n",
    "\n",
    "    self.backbone = nn.Sequential(OrderedDict(layers))\n",
    "    self.classifier = nn.Linear(128, 4)\n",
    "    # self.classifier = nn.Linear(128, 4)\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x, _ = self.gru1(x)\n",
    "    x = self.relu1(x)\n",
    "    x, _ = self.gru2(x)\n",
    "    x = self.relu2(x)\n",
    "    x = x.reshape(-1, 32, self.seq_len)\n",
    "    x = self.backbone(x)\n",
    "    x = x.reshape(-1, 128)\n",
    "    x = self.classifier(x)\n",
    "    x = self.softmax(x)\n",
    "\n",
    "    return x\n",
    "  \n",
    "model = MyModel().cuda()\n",
    "## show model summary\n",
    "print(model.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  callbacks = None\n",
    ") -> None:\n",
    "  model.train()\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Reset the gradients (from the last iteration)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward inference\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Update optimizer and LR scheduler\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if callbacks is not None:\n",
    "        for callback in callbacks:\n",
    "            callback()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  verbose=True,\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False,\n",
    "                              disable=not verbose):\n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Inference\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Convert logits to class indices\n",
    "    outputs = outputs.argmax(dim=1)\n",
    "\n",
    "    # Update metrics\n",
    "    num_samples += targets.size(0)\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()\n",
    "\n",
    "# save checkpoint to local file\n",
    "def save_checkpoint(\n",
    "  model: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  epoch: int,\n",
    "  accuracy: float,\n",
    "  path: str,\n",
    ") -> None:\n",
    "  torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'scheduler': scheduler.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'accuracy': accuracy,\n",
    "  }, path)\n",
    "\n",
    "\n",
    "# load checkpoint from local file\n",
    "def load_checkpoint(\n",
    "  model: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  path: str,\n",
    ") -> None:\n",
    "  checkpoint = torch.load(path)\n",
    "\n",
    "  model.load_state_dict(checkpoint['model'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "  scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "  return checkpoint['epoch'], checkpoint['accuracy']\n",
    "\n",
    "# train model\n",
    "def run(\n",
    "  model: nn.Module,\n",
    "  train_dataloader: DataLoader,\n",
    "  valid_dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  num_epochs: int,\n",
    "  checkpoint_path: str,\n",
    "  verbose=True,\n",
    ") -> None:\n",
    "  best_accuracy = 0.0\n",
    "\n",
    "  for epoch in tqdm(range(num_epochs)):\n",
    "    # Train for one epoch\n",
    "    train(model, train_dataloader, criterion, optimizer, scheduler)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    accuracy = evaluate(model, valid_dataloader, verbose)\n",
    "\n",
    "    # Save checkpoint\n",
    "    if accuracy > best_accuracy:\n",
    "      best_accuracy = accuracy\n",
    "      save_checkpoint(model, optimizer, scheduler, epoch, accuracy,\n",
    "                      checkpoint_path)\n",
    "\n",
    "    if verbose:\n",
    "      print(f'Epoch: {epoch + 1:03d} | '\n",
    "            f'accuracy = {accuracy:.2f} | '\n",
    "            f'best_accuracy = {best_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint from epoch 9 with accuracy 87.76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca342ed7c4f42f7ae3261db76e0534f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb60a63c04d7484cb9f9601f9542f556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da04be56b3004676a256876f0c6a4327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | accuracy = 28.03 | best_accuracy = 28.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0484e443f2443ee9307b6d948adcf35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23d9fea44924730ab663030c0540153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002 | accuracy = 28.26 | best_accuracy = 28.26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad34385e2a054dd59fa04235665f3650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\heesu\\univ\\2023-2\\mobile-computing\\mobile-computing-project\\ml\\model.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     epoch, accuracy \u001b[39m=\u001b[39m load_checkpoint(model, optimizer, scheduler, checkpoint_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoad checkpoint from epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m with accuracy \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m run(model, train_dataloader, test_dataloader, criterion, optimizer, scheduler, \u001b[39m10\u001b[39m, checkpoint_path, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\heesu\\univ\\2023-2\\mobile-computing\\mobile-computing-project\\ml\\model.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m best_accuracy \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(num_epochs)):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m   \u001b[39m# Train for one epoch\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m   train(model, train_dataloader, criterion, optimizer, scheduler)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m   \u001b[39m# Evaluate on validation set\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m   accuracy \u001b[39m=\u001b[39m evaluate(model, valid_dataloader, verbose)\n",
      "\u001b[1;32mc:\\Users\\heesu\\univ\\2023-2\\mobile-computing\\mobile-computing-project\\ml\\model.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   model: nn\u001b[39m.\u001b[39mModule,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   dataloader: DataLoader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m   \u001b[39mfor\u001b[39;00m inputs, targets \u001b[39min\u001b[39;00m tqdm(dataloader, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# Move the data from CPU to GPU\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[1;32mc:\\Users\\heesu\\anaconda3\\Lib\\site-packages\\tqdm\\notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[1;32m--> 254\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[0;32m    255\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    256\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m    257\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heesu\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\heesu\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\heesu\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\heesu\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\heesu\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mc:\\Users\\heesu\\univ\\2023-2\\mobile-computing\\mobile-computing-project\\ml\\model.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[idx]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     sample \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(sample, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels\u001b[39m.\u001b[39miloc[idx,\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X25sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(label, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "num_epochs = 10\n",
    "steps_per_epoch = len(train_dataloader)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler =  torch.optim.lr_scheduler.StepLR(optimizer, step_size=steps_per_epoch, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "checkpoint_path = \"checkpoint.pth\"\n",
    "# if checkpoint exist then load checkpoint\n",
    "if os.path.exists(checkpoint_path):\n",
    "    epoch, accuracy = load_checkpoint(model, optimizer, scheduler, checkpoint_path)\n",
    "    print(f\"Load checkpoint from epoch {epoch} with accuracy {accuracy:.2f}\")\n",
    "    \n",
    "run(model, train_dataloader, test_dataloader, criterion, optimizer, scheduler, 10, checkpoint_path, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
