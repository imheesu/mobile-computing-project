{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing torchprofile...\n",
      "Requirement already satisfied: torchprofile in c:\\users\\heesu\\anaconda3\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchprofile) (1.24.3)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchprofile) (2.1.1)\n",
      "Requirement already satisfied: torchvision>=0.4 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchprofile) (0.16.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (2023.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchvision>=0.4->torchprofile) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchvision>=0.4->torchprofile) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.4->torchprofile) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\n",
      "All required packages have been successfully installed!\n"
     ]
    }
   ],
   "source": [
    "print('Installing torchprofile...')\n",
    "!pip install torchprofile\n",
    "print('All required packages have been successfully installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from collections import OrderedDict, defaultdict\n",
    "from typing import Union, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56379, 90, 6)\n",
      "(56379, 1)\n",
      "(37530, 90, 6)\n",
      "(37530, 1)\n"
     ]
    }
   ],
   "source": [
    "annotation_train_path = './dataset/annotation_train.csv'\n",
    "dataset_train_path = './dataset/data_train.npy'\n",
    "annotation_test_path = './dataset/annotation_test.csv'\n",
    "dataset_test_path = './dataset/data_test.npy'\n",
    "\n",
    "class RunningDataset(Dataset):\n",
    "    def __init__(self,annotation_path, dataset_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.labels = pd.read_csv(annotation_path, header=None)\n",
    "        self.data = np.load(dataset_path)\n",
    "\n",
    "        print (self.data.shape)\n",
    "        print (self.labels.shape)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        sample = torch.tensor(sample, dtype=torch.float32)\n",
    "        label = self.labels.iloc[idx,0]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample, label\n",
    "\n",
    "train_dataset = RunningDataset(annotation_train_path, dataset_train_path)\n",
    "test_dataset = RunningDataset(annotation_test_path, dataset_test_path)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=50,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=50,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (gru1): GRU(6, 32, batch_first=True)\n",
      "  (relu1): ReLU()\n",
      "  (gru2): GRU(32, 32, batch_first=True)\n",
      "  (relu2): ReLU()\n",
      "  (backbone): Sequential(\n",
      "    (conv0): Conv1d(32, 64, kernel_size=(2,), stride=(2,))\n",
      "    (relu0): ReLU()\n",
      "    (pool0): MaxPool1d(kernel_size=4, stride=4, padding=1, dilation=1, ceil_mode=False)\n",
      "    (conv1): Conv1d(64, 128, kernel_size=(2,), stride=(1,))\n",
      "    (relu1): ReLU()\n",
      "    (adaptivePoll0): AdaptiveAvgPool1d(output_size=1)\n",
      "    (bn0): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=128, out_features=4, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "\n",
    "    layers = []\n",
    "    counts = defaultdict(int)\n",
    "    self.seq_len = 90\n",
    "\n",
    "    def add(name: str, layer: nn.Module) -> None:\n",
    "      layers.append((f\"{name}{counts[name]}\", layer))\n",
    "      counts[name] += 1\n",
    "\n",
    "    self.gru1 = nn.GRU(input_size=6, hidden_size=32, batch_first=True)\n",
    "    self.relu1 = nn.ReLU()\n",
    "    self.gru2 = nn.GRU(input_size=32, hidden_size=32, batch_first=True)\n",
    "    self.relu2 = nn.ReLU()\n",
    "    add(\"conv\", nn.Conv1d(32, 64, 2, stride=2))\n",
    "    add(\"relu\", nn.ReLU())\n",
    "    add(\"pool\", nn.MaxPool1d(4, padding=1))\n",
    "    add(\"conv\", nn.Conv1d(64, 128, 2, stride=1))\n",
    "    add(\"relu\", nn.ReLU())\n",
    "    add(\"adaptivePoll\",nn.AdaptiveAvgPool1d(1))\n",
    "    add(\"bn\", nn.BatchNorm1d(128, eps=1e-06))\n",
    "\n",
    "    self.backbone = nn.Sequential(OrderedDict(layers))\n",
    "    self.classifier = nn.Linear(128, 4)\n",
    "    # self.classifier = nn.Linear(128, 4)\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x, _ = self.gru1(x)\n",
    "    x = self.relu1(x)\n",
    "    x, _ = self.gru2(x)\n",
    "    x = self.relu2(x)\n",
    "    x = x.reshape(-1, 32, self.seq_len)\n",
    "    x = self.backbone(x)\n",
    "    x = x.reshape(-1, 128)\n",
    "    x = self.classifier(x)\n",
    "    x = self.softmax(x)\n",
    "\n",
    "    return x\n",
    "  \n",
    "model = MyModel().cuda()\n",
    "## show model summary\n",
    "print(model.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  callbacks = None\n",
    ") -> None:\n",
    "  model.train()\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Reset the gradients (from the last iteration)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward inference\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Update optimizer and LR scheduler\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if callbacks is not None:\n",
    "        for callback in callbacks:\n",
    "            callback()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  verbose=True,\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False,\n",
    "                              disable=not verbose):\n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Inference\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Convert logits to class indices\n",
    "    outputs = outputs.argmax(dim=1)\n",
    "\n",
    "    # Update metrics\n",
    "    num_samples += targets.size(0)\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()\n",
    "\n",
    "# save checkpoint to local file\n",
    "def save_checkpoint(\n",
    "  model: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  epoch: int,\n",
    "  accuracy: float,\n",
    "  path: str,\n",
    ") -> None:\n",
    "  torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'scheduler': scheduler.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'accuracy': accuracy,\n",
    "  }, path)\n",
    "\n",
    "\n",
    "# load checkpoint from local file\n",
    "def load_checkpoint(\n",
    "  model: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  path: str,\n",
    ") -> None:\n",
    "  checkpoint = torch.load(path)\n",
    "\n",
    "  model.load_state_dict(checkpoint['model'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "  scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "  return checkpoint['epoch'], checkpoint['accuracy']\n",
    "\n",
    "# train model\n",
    "def run(\n",
    "  model: nn.Module,\n",
    "  train_dataloader: DataLoader,\n",
    "  valid_dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  num_epochs: int,\n",
    "  checkpoint_path: str,\n",
    "  verbose=True,\n",
    ") -> None:\n",
    "  best_accuracy = 0.0\n",
    "\n",
    "  for epoch in tqdm(range(num_epochs)):\n",
    "    # Train for one epoch\n",
    "    train(model, train_dataloader, criterion, optimizer, scheduler)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    accuracy = evaluate(model, valid_dataloader, verbose)\n",
    "\n",
    "    # Save checkpoint\n",
    "    if accuracy > best_accuracy:\n",
    "      best_accuracy = accuracy\n",
    "      save_checkpoint(model, optimizer, scheduler, epoch, accuracy,\n",
    "                      checkpoint_path)\n",
    "\n",
    "    if verbose:\n",
    "      print(f'Epoch: {epoch + 1:03d} | '\n",
    "            f'accuracy = {accuracy:.2f} | '\n",
    "            f'best_accuracy = {best_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load checkpoint from epoch 5 with accuracy 87.82\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bf8faff353465fbea8e7525790b433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a7c0e6ce8e4a2ba5dad8b5f9f9215e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32eada543784c55bb6d86f7c187364b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | accuracy = 87.72 | best_accuracy = 87.72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4642ada4577e4322859f2d2313515989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e08f29497f14f1388817d4a6e74243e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002 | accuracy = 87.65 | best_accuracy = 87.72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5e293fe1884dbaa50aa90a73b53927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffbe1c3e718b4e6ba7cf68d1f20d74c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003 | accuracy = 87.67 | best_accuracy = 87.72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9478e5ab2e7744d1908f53627991a893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca0a87ad6664c369cd1063bb95fa20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004 | accuracy = 87.76 | best_accuracy = 87.76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59728a2cce6547ad841d6ba1fe9e5401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2cfeceae3734c159c05fe6cadce2ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005 | accuracy = 87.73 | best_accuracy = 87.76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a965247dcbec46a1a837d5e56ded845b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5196090fea244c749ead4e706e03f462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006 | accuracy = 87.72 | best_accuracy = 87.76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e366ba9ee42b4130a306414110117786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21548e0d6732494d8fc44770ea052d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007 | accuracy = 87.73 | best_accuracy = 87.76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c34ae6c5a4045e59b3234adabcbac83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62990f5853b4081a413de8476a13565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008 | accuracy = 87.61 | best_accuracy = 87.76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c23191d01b4aa08d0e8641d7f4f667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c747a2b2dba47a7a46d2a206c603f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009 | accuracy = 87.76 | best_accuracy = 87.76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5ee3193b7b4bc699147eb564a50180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c715890d9a47fd855a6d787a0d5649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010 | accuracy = 87.71 | best_accuracy = 87.76\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "num_epochs = 10\n",
    "steps_per_epoch = len(train_dataloader)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "scheduler =  torch.optim.lr_scheduler.StepLR(optimizer, step_size=steps_per_epoch, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "checkpoint_path = \"checkpoint.pth\"\n",
    "# if checkpoint exist then load checkpoint\n",
    "if os.path.exists(checkpoint_path):\n",
    "    epoch, accuracy = load_checkpoint(model, optimizer, scheduler, checkpoint_path)\n",
    "    print(f\"Load checkpoint from epoch {epoch} with accuracy {accuracy:.2f}\")\n",
    "    \n",
    "run(model, train_dataloader, test_dataloader, criterion, optimizer, scheduler, 10, checkpoint_path, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
