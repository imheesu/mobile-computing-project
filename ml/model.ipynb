{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing torchprofile...\n",
      "Requirement already satisfied: torchprofile in c:\\users\\heesu\\anaconda3\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchprofile) (1.24.3)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchprofile) (2.1.1)\n",
      "Requirement already satisfied: torchvision>=0.4 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchprofile) (0.16.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (2023.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchvision>=0.4->torchprofile) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchvision>=0.4->torchprofile) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.4->torchprofile) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\n",
      "All required packages have been successfully installed!\n"
     ]
    }
   ],
   "source": [
    "print('Installing torchprofile...')\n",
    "!pip install torchprofile\n",
    "print('All required packages have been successfully installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78422, 80, 6)\n",
      "(78422, 1)\n",
      "(16267, 80, 6)\n",
      "(16267, 1)\n"
     ]
    }
   ],
   "source": [
    "annotation_train_path = './dataset/annotation_train.csv'\n",
    "dataset_train_path = './dataset/data_train.npy'\n",
    "annotation_test_path = './dataset/annotation_test.csv'\n",
    "dataset_test_path = './dataset/data_test.npy'\n",
    "\n",
    "class RunningDataset(Dataset):\n",
    "    def __init__(self,annotation_path, dataset_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.labels = pd.read_csv(annotation_path, header=None)\n",
    "        self.data = np.load(dataset_path)\n",
    "\n",
    "        print (self.data.shape)\n",
    "        print (self.labels.shape)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        sample = torch.tensor(sample, dtype=torch.float32)\n",
    "        label = self.labels.iloc[idx,0]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample, label\n",
    "\n",
    "train_dataset = RunningDataset(annotation_train_path, dataset_train_path)\n",
    "test_dataset = RunningDataset(annotation_test_path, dataset_test_path)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=300,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=300,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (gru1): GRU(6, 42, batch_first=True)\n",
      "  (relu1): ReLU()\n",
      "  (gru2): GRU(42, 42, batch_first=True)\n",
      "  (relu2): ReLU()\n",
      "  (backbone): Sequential(\n",
      "    (conv0): Conv1d(42, 80, kernel_size=(2,), stride=(2,))\n",
      "    (relu0): ReLU()\n",
      "    (pool0): MaxPool1d(kernel_size=4, stride=4, padding=1, dilation=1, ceil_mode=False)\n",
      "    (conv1): Conv1d(80, 196, kernel_size=(2,), stride=(1,))\n",
      "    (relu1): ReLU()\n",
      "    (adaptivePoll0): AdaptiveAvgPool1d(output_size=1)\n",
      "    (bn0): BatchNorm1d(196, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=196, out_features=4, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "  def __init__(self, fc_size=196, hidden_size=42) -> None:\n",
    "    super().__init__()\n",
    "\n",
    "    layers = []\n",
    "    counts = defaultdict(int)\n",
    "    self.seq_len = 80\n",
    "    self.hidden_size = hidden_size\n",
    "    self.fc_size = fc_size\n",
    "\n",
    "    def add(name: str, layer: nn.Module) -> None:\n",
    "      layers.append((f\"{name}{counts[name]}\", layer))\n",
    "      counts[name] += 1\n",
    "\n",
    "    self.gru1 = nn.GRU(input_size=6, hidden_size=self.hidden_size, batch_first=True)\n",
    "    self.relu1 = nn.ReLU()\n",
    "    self.gru2 = nn.GRU(input_size=self.hidden_size, hidden_size=self.hidden_size, batch_first=True)\n",
    "    self.relu2 = nn.ReLU()\n",
    "    add(\"conv\", nn.Conv1d(self.hidden_size, 80, 2, stride=2))\n",
    "    add(\"relu\", nn.ReLU())\n",
    "    add(\"pool\", nn.MaxPool1d(4, padding=1))\n",
    "    add(\"conv\", nn.Conv1d(80, self.fc_size, 2, stride=1))\n",
    "    add(\"relu\", nn.ReLU())\n",
    "    add(\"adaptivePoll\",nn.AdaptiveAvgPool1d(1))\n",
    "    add(\"bn\", nn.BatchNorm1d(self.fc_size, eps=1e-06))\n",
    "\n",
    "    self.backbone = nn.Sequential(OrderedDict(layers))\n",
    "    self.classifier = nn.Linear(self.fc_size, 4)\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x, _ = self.gru1(x)\n",
    "    x = self.relu1(x)\n",
    "    x, _ = self.gru2(x)\n",
    "    x = self.relu2(x)\n",
    "    x = x.reshape(-1, self.hidden_size, self.seq_len)\n",
    "    x = self.backbone(x)\n",
    "    x = x.reshape(-1, self.fc_size)\n",
    "    x = self.classifier(x)\n",
    "    x = self.softmax(x)\n",
    "\n",
    "    return x\n",
    "  \n",
    "model = MyModel().cuda()\n",
    "## show model summary\n",
    "print(model.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  callbacks = None\n",
    ") -> None:\n",
    "  model.train()\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Reset the gradients (from the last iteration)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward inference\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Update optimizer and LR scheduler\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if callbacks is not None:\n",
    "        for callback in callbacks:\n",
    "            callback()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  verbose=True,\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False,\n",
    "                              disable=not verbose):\n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Inference\n",
    "    outputs = model(inputs)\n",
    "   \n",
    "    outputs = outputs.argmax(dim=1)\n",
    "\n",
    "    # Update metrics\n",
    "    num_samples += targets.size(0)\n",
    "    # abnormal = 0, normal = 3\n",
    "    outputs[outputs < 3] = 0\n",
    "    targets[targets < 3] = 0\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()\n",
    "\n",
    "# save checkpoint to local file\n",
    "def save_checkpoint(\n",
    "  model: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  epoch: int,\n",
    "  accuracy: float,\n",
    "  path: str,\n",
    ") -> None:\n",
    "  torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'scheduler': scheduler.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'accuracy': accuracy,\n",
    "  }, f\"{path}\")\n",
    "\n",
    "\n",
    "# load checkpoint from local file\n",
    "def load_checkpoint(\n",
    "  model: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  path: str,\n",
    ") -> None:\n",
    "  checkpoint = torch.load(path)\n",
    "\n",
    "  model.load_state_dict(checkpoint['model'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "  scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "  return checkpoint['epoch'], checkpoint['accuracy']\n",
    "\n",
    "# train model\n",
    "def run(\n",
    "  model: nn.Module,\n",
    "  train_dataloader: DataLoader,\n",
    "  valid_dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  num_epochs: int,\n",
    "  checkpoint_path: str,\n",
    "  verbose=True,\n",
    ") -> None:\n",
    "  best_accuracy = 0.0\n",
    "\n",
    "  for epoch in tqdm(range(num_epochs)):\n",
    "    # Train for one epoch\n",
    "    train(model, train_dataloader, criterion, optimizer, scheduler)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    accuracy = evaluate(model, valid_dataloader, verbose)\n",
    "    # Save checkpoint\n",
    "    if accuracy > best_accuracy:\n",
    "      best_accuracy = accuracy\n",
    "      save_checkpoint(model, optimizer, scheduler, epoch, accuracy,\n",
    "                      checkpoint_path)\n",
    "\n",
    "    if verbose:\n",
    "      print(f'Epoch: {epoch + 1:03d} | '\n",
    "            f'accuracy = {accuracy:.2f} |'\n",
    "            f'best_accuracy = {best_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d100af3204b144db871080a1e9365bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ec4d8a035847b1a66072b4db970bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a563a095c7746118d608deacaf47c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | accuracy = 80.84 |best_accuracy = 80.84\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cfb4eb04b24514aa889ab316877221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23ef9e8ea8749adbf8addfd784e85a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002 | accuracy = 81.50 |best_accuracy = 81.50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042fa426a5f246108876791f1d8aea6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8d737bc59249c48e69cee953c49daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003 | accuracy = 81.68 |best_accuracy = 81.68\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe983f22ff0244c6a9ee4e24454ada1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab42c1b6c464b8c9fe37339ff2e223b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004 | accuracy = 81.78 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf62cf8f5404dbeb6473051a761b1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aaa1cf110204b8f83a6c3bbb6726915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005 | accuracy = 81.67 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813c0fba98184e6c82e8040093306f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e41e1827e1b4a15b19ded92367ff297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006 | accuracy = 81.74 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86ef6e4f88d487687c5f876e78ebdd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00903e65fb8444bd8775c12ea3ac325c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007 | accuracy = 81.70 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b60191dac4d4e7b87747b2bbed9e672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae4ed14b05849debfd260712f568f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008 | accuracy = 81.67 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667ab4fb56ac4164b845713a14ee3ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4b6897193c4dfb8ee96f15c5391065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009 | accuracy = 81.71 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c72e51bd4594388a935599f2e1af232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece485249d964a178a306e2a7fdbd87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010 | accuracy = 81.67 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9768229dfad24eb1803bd76c89874ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9df76fb925f4f15b0d84ce514e0f083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011 | accuracy = 81.70 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d35e00a7fb42b9bab886a4d2d1befe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ffc9ceb21740b68d191f831cea0a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012 | accuracy = 81.65 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582f33b82b9b411cb712102b1acdaa69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cd7f3560c943d193e0f9c24b046025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013 | accuracy = 81.63 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab8090c6fac40e2a6ea59d38a0eaef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8601b5754e0f48a2aa7668c466a5c192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014 | accuracy = 81.72 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84ac64596094e5781fef44e06b23eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5f0a7a469d458187a80d7b260e3ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015 | accuracy = 81.71 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456fec91e4044bae97d4402533e0f657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf581c6e5d23470bbcf80ce17fc840d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016 | accuracy = 81.67 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f5cc27d3654a9a9f543dfb3ca41d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ff3babad2c4287bd01a237eb058f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017 | accuracy = 81.65 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6729f962d04448399ea1b61c5c36c10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f971ec5ec0b14ad58baf66488d107219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018 | accuracy = 81.64 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0042762790749e2adb7bd2980adf3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b3f7c2b5a948308bbdaf05b29c8c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019 | accuracy = 81.67 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ce054d6f5146c085314c250717ed33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae37d6efdf084f0a9ff8b224eda411b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020 | accuracy = 81.69 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb601e9d8da40b48fda8100b6a45e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb70c89d243648999d6a2b544eb855cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 021 | accuracy = 81.62 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389131491f794866ae88c8d01abb7185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426a8d819d21480089fa677920eb7f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 022 | accuracy = 81.60 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec338bb89d694daa8d9f440eaa21d2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd4dca8062641da93b5b9a80fb3ff25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023 | accuracy = 81.69 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417a7875ce2f452fa34642f4c1d89d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138042222756417f99af4db7a9f64223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024 | accuracy = 81.69 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb554965b6c8451a923289a5b2f02a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a31931810846dfb66c68b190cce966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025 | accuracy = 81.71 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7b9b26749d4e22a54a7a620e4e85f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647f9bd5c5a44a3488d27ef68173bab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 026 | accuracy = 81.72 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0e29048f144be3bf769f828faa68db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9adaebc0b64481af8e4445ee1d2de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 027 | accuracy = 81.67 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc94302ccfe4b31b3cc2634217eca1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838c0ead6c884a258749d09e94b6af39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 028 | accuracy = 81.69 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3dac78d9be40159a0bbceb21682de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa14679cb754a47888b75ffdb5b667e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 029 | accuracy = 81.67 |best_accuracy = 81.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d77419b6bb405ca99b37266037f6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99434257352e4f34be03df851c21fd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 030 | accuracy = 81.70 |best_accuracy = 81.78\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "num_epochs =15\n",
    "steps_per_epoch = len(train_dataloader)\n",
    "\n",
    "def run_per_model(model,lr=2e-3,gamma=0.5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler =  torch.optim.lr_scheduler.StepLR(optimizer, step_size=steps_per_epoch, gamma=gamma)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    checkpoint_path = \"checkpoint.pth\"\n",
    "    run(model, train_dataloader, test_dataloader, criterion, optimizer, scheduler, num_epochs, checkpoint_path, verbose=True)\n",
    "\n",
    "\n",
    "run_per_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MyModel:\n\tMissing key(s) in state_dict: \"gru1.weight_ih_l0\", \"gru1.weight_hh_l0\", \"gru1.bias_ih_l0\", \"gru1.bias_hh_l0\", \"gru2.weight_ih_l0\", \"gru2.weight_hh_l0\", \"gru2.bias_ih_l0\", \"gru2.bias_hh_l0\", \"backbone.conv0.weight\", \"backbone.conv0.bias\", \"backbone.conv1.weight\", \"backbone.conv1.bias\", \"backbone.bn0.weight\", \"backbone.bn0.bias\", \"backbone.bn0.running_mean\", \"backbone.bn0.running_var\", \"classifier.weight\", \"classifier.bias\". \n\tUnexpected key(s) in state_dict: \"model\", \"optimizer\", \"scheduler\", \"epoch\", \"accuracy\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\heesu\\univ\\2023-2\\mobile-computing\\mobile-computing-project\\ml\\model.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(model: nn\u001b[39m.\u001b[39mModule, path: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(path))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m load_model(model, \u001b[39m\"\u001b[39m\u001b[39mcheckpoint.pth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# evaluate model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m accuracy \u001b[39m=\u001b[39m evaluate(model, test_dataloader, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\heesu\\univ\\2023-2\\mobile-computing\\mobile-computing-project\\ml\\model.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(model: nn\u001b[39m.\u001b[39mModule, path: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(path))\n",
      "File \u001b[1;32mc:\\Users\\heesu\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2147\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   2148\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2149\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2152\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2153\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2154\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MyModel:\n\tMissing key(s) in state_dict: \"gru1.weight_ih_l0\", \"gru1.weight_hh_l0\", \"gru1.bias_ih_l0\", \"gru1.bias_hh_l0\", \"gru2.weight_ih_l0\", \"gru2.weight_hh_l0\", \"gru2.bias_ih_l0\", \"gru2.bias_hh_l0\", \"backbone.conv0.weight\", \"backbone.conv0.bias\", \"backbone.conv1.weight\", \"backbone.conv1.bias\", \"backbone.bn0.weight\", \"backbone.bn0.bias\", \"backbone.bn0.running_mean\", \"backbone.bn0.running_var\", \"classifier.weight\", \"classifier.bias\". \n\tUnexpected key(s) in state_dict: \"model\", \"optimizer\", \"scheduler\", \"epoch\", \"accuracy\". "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to synchronously open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\heesu\\univ\\2023-2\\mobile-computing\\mobile-computing-project\\ml\\model.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# load model using tensorflow from model.h5\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39mmodel.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# convert model to tflite format\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/heesu/univ/2023-2/mobile-computing/mobile-computing-project/ml/model.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m converter \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mlite\u001b[39m.\u001b[39mTFLiteConverter\u001b[39m.\u001b[39mfrom_keras_model(model)\n",
      "File \u001b[1;32mc:\\Users\\heesu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m    255\u001b[0m         filepath,\n\u001b[0;32m    256\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[0;32m    257\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[0;32m    258\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m    263\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39mcustom_objects, \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    264\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\heesu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\heesu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[39m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[39m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[39m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39;49mswmr)\n\u001b[0;32m    564\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\heesu\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m swmr \u001b[39mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, flags, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[0;32m    236\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, h5f\u001b[39m.\u001b[39mACC_RDWR, fapl\u001b[39m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to synchronously open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "# convert model to tflite format\n",
    "import tensorflow as tf\n",
    "\n",
    "# load model using tensorflow from model.h5\n",
    "model = tf.keras.models.load_model('./model.h5')\n",
    "\n",
    "# convert model to tflite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"model.tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
