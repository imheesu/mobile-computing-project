{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing torchprofile...\n",
      "Requirement already satisfied: torchprofile in c:\\users\\heesu\\anaconda3\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchprofile) (1.24.3)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchprofile) (2.1.1)\n",
      "Requirement already satisfied: torchvision>=0.4 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchprofile) (0.16.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torch>=1.4->torchprofile) (2023.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchvision>=0.4->torchprofile) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from torchvision>=0.4->torchprofile) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.4->torchprofile) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.4->torchprofile) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\heesu\\anaconda3\\lib\\site-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\n",
      "All required packages have been successfully installed!\n"
     ]
    }
   ],
   "source": [
    "print('Installing torchprofile...')\n",
    "!pip install torchprofile\n",
    "print('All required packages have been successfully installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78422, 80, 6)\n",
      "(78422, 1)\n",
      "(16267, 80, 6)\n",
      "(16267, 1)\n"
     ]
    }
   ],
   "source": [
    "annotation_train_path = './dataset/annotation_train.csv'\n",
    "dataset_train_path = './dataset/data_train.npy'\n",
    "annotation_test_path = './dataset/annotation_test.csv'\n",
    "dataset_test_path = './dataset/data_test.npy'\n",
    "\n",
    "class RunningDataset(Dataset):\n",
    "    def __init__(self,annotation_path, dataset_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.labels = pd.read_csv(annotation_path, header=None)\n",
    "        self.data = np.load(dataset_path)\n",
    "\n",
    "        print (self.data.shape)\n",
    "        print (self.labels.shape)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        sample = torch.tensor(sample, dtype=torch.float32)\n",
    "        label = self.labels.iloc[idx,0]\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample, label\n",
    "\n",
    "train_dataset = RunningDataset(annotation_train_path, dataset_train_path)\n",
    "test_dataset = RunningDataset(annotation_test_path, dataset_test_path)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=300,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=300,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (gru1): GRU(6, 42, batch_first=True)\n",
      "  (relu1): ReLU()\n",
      "  (gru2): GRU(42, 42, batch_first=True)\n",
      "  (relu2): ReLU()\n",
      "  (backbone): Sequential(\n",
      "    (conv0): Conv1d(42, 80, kernel_size=(2,), stride=(2,))\n",
      "    (relu0): ReLU()\n",
      "    (pool0): MaxPool1d(kernel_size=4, stride=4, padding=1, dilation=1, ceil_mode=False)\n",
      "    (conv1): Conv1d(80, 196, kernel_size=(2,), stride=(1,))\n",
      "    (relu1): ReLU()\n",
      "    (adaptivePoll0): AdaptiveAvgPool1d(output_size=1)\n",
      "    (bn0): BatchNorm1d(196, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=196, out_features=4, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "  def __init__(self, fc_size=196, hidden_size=42) -> None:\n",
    "    super().__init__()\n",
    "\n",
    "    layers = []\n",
    "    counts = defaultdict(int)\n",
    "    self.seq_len = 80\n",
    "    self.hidden_size = hidden_size\n",
    "    self.fc_size = fc_size\n",
    "\n",
    "    def add(name: str, layer: nn.Module) -> None:\n",
    "      layers.append((f\"{name}{counts[name]}\", layer))\n",
    "      counts[name] += 1\n",
    "\n",
    "    self.gru1 = nn.GRU(input_size=6, hidden_size=self.hidden_size, batch_first=True)\n",
    "    self.relu1 = nn.ReLU()\n",
    "    self.gru2 = nn.GRU(input_size=self.hidden_size, hidden_size=self.hidden_size, batch_first=True)\n",
    "    self.relu2 = nn.ReLU()\n",
    "    add(\"conv\", nn.Conv1d(self.hidden_size, 80, 2, stride=2))\n",
    "    add(\"relu\", nn.ReLU())\n",
    "    add(\"pool\", nn.MaxPool1d(4, padding=1))\n",
    "    add(\"conv\", nn.Conv1d(80, self.fc_size, 2, stride=1))\n",
    "    add(\"relu\", nn.ReLU())\n",
    "    add(\"adaptivePoll\",nn.AdaptiveAvgPool1d(1))\n",
    "    add(\"bn\", nn.BatchNorm1d(self.fc_size, eps=1e-06))\n",
    "\n",
    "    self.backbone = nn.Sequential(OrderedDict(layers))\n",
    "    self.classifier = nn.Linear(self.fc_size, 4)\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x, _ = self.gru1(x)\n",
    "    x = self.relu1(x)\n",
    "    x, _ = self.gru2(x)\n",
    "    x = self.relu2(x)\n",
    "    x = x.reshape(-1, self.hidden_size, self.seq_len)\n",
    "    x = self.backbone(x)\n",
    "    x = x.reshape(-1, self.fc_size)\n",
    "    x = self.classifier(x)\n",
    "    x = self.softmax(x)\n",
    "\n",
    "    return x\n",
    "  \n",
    "model = MyModel().cuda()\n",
    "## show model summary\n",
    "print(model.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  callbacks = None\n",
    ") -> None:\n",
    "  model.train()\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Reset the gradients (from the last iteration)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward inference\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Update optimizer and LR scheduler\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if callbacks is not None:\n",
    "        for callback in callbacks:\n",
    "            callback()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  verbose=True,\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False,\n",
    "                              disable=not verbose):\n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Inference\n",
    "    outputs = model(inputs)\n",
    "   \n",
    "    outputs = outputs.argmax(dim=1)\n",
    "\n",
    "    # Update metrics\n",
    "    num_samples += targets.size(0)\n",
    "    # abnormal = 0, normal = 3\n",
    "    outputs[outputs < 3] = 0\n",
    "    targets[targets < 3] = 0\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()\n",
    "\n",
    "# save checkpoint to local file\n",
    "def save_checkpoint(\n",
    "  model: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  epoch: int,\n",
    "  accuracy: float,\n",
    "  path: str,\n",
    ") -> None:\n",
    "  torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'scheduler': scheduler.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'accuracy': accuracy,\n",
    "  }, f\"{path}\")\n",
    "\n",
    "\n",
    "# load checkpoint from local file\n",
    "def load_checkpoint(\n",
    "  model: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  path: str,\n",
    ") -> None:\n",
    "  checkpoint = torch.load(path)\n",
    "\n",
    "  model.load_state_dict(checkpoint['model'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "  scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "  return checkpoint['epoch'], checkpoint['accuracy']\n",
    "\n",
    "# train model\n",
    "def run(\n",
    "  model: nn.Module,\n",
    "  train_dataloader: DataLoader,\n",
    "  valid_dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  num_epochs: int,\n",
    "  checkpoint_path: str,\n",
    "  verbose=True,\n",
    ") -> None:\n",
    "  best_accuracy = 0.0\n",
    "\n",
    "  for epoch in tqdm(range(num_epochs)):\n",
    "    # Train for one epoch\n",
    "    train(model, train_dataloader, criterion, optimizer, scheduler)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    accuracy = evaluate(model, valid_dataloader, verbose)\n",
    "    # Save checkpoint\n",
    "    if accuracy > best_accuracy:\n",
    "      best_accuracy = accuracy\n",
    "      save_checkpoint(model, optimizer, scheduler, epoch, accuracy,\n",
    "                      checkpoint_path)\n",
    "\n",
    "    if verbose:\n",
    "      print(f'Epoch: {epoch + 1:03d} | '\n",
    "            f'accuracy = {accuracy:.2f} |'\n",
    "            f'best_accuracy = {best_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2a044b949f4ee5b3ae1003fa8f739d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b9ee9cac3547d2a8738fec0cd9d7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b5902d38bd4f5e80f5d7851d169c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | accuracy = 78.32 |best_accuracy = 78.32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955845549cb54dea825189db708c8cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7544d83c94894eb79219bdd400c69d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002 | accuracy = 79.39 |best_accuracy = 79.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e0cf50d7614ceabf5aea36542d282c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4afd6e95db4475a150acbc844fd456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003 | accuracy = 77.99 |best_accuracy = 79.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d504eca09734c758061252a83ed3bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b3f31795b140ccab1835b6b91b5e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004 | accuracy = 77.65 |best_accuracy = 79.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fb4af78ee94955832eb6beed77c69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4461c51f2904b81bf905c22275f397d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005 | accuracy = 77.68 |best_accuracy = 79.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326b7f4497a048fe8e0831c453764b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d78bfcc1d1b4bddad52e34adf35c71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006 | accuracy = 77.62 |best_accuracy = 79.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50391f41900b48199e0a2733415ddf99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278b1a2604b64fafbd7bd86191dc412b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007 | accuracy = 77.73 |best_accuracy = 79.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222aee987657406fb7f0db63249a44c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c8fbe0937b4f0ab94214a625e44959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008 | accuracy = 77.46 |best_accuracy = 79.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0724754b0d4a1c9ca522f3c449b084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da23ee1850142559ab47bca1eb857af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009 | accuracy = 78.24 |best_accuracy = 79.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3eabd331234e52b5638b3f408c0d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffe2b2d104747098e4ca76468a91441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010 | accuracy = 77.66 |best_accuracy = 79.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1804553dfe4dca8ac9692a05949551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0f314c17724a6e8cf86cd13f6ca09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011 | accuracy = 77.78 |best_accuracy = 79.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df07044799124350accb5892a16ae0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0952f7a44e4e5e98a7953352375766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012 | accuracy = 77.61 |best_accuracy = 79.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db6495f6ade4d47be8f75e092c5711e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd99528f1bdc477692cc2297805c11d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013 | accuracy = 77.67 |best_accuracy = 79.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecef98537f3e4c19ae13e98fe2f845ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123abc639b6d4c769d85e1ddf89d5bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014 | accuracy = 77.72 |best_accuracy = 79.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af641940cca046348f8321b09c83e953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0147ab1d2f35454ebb9c74ddffca4db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015 | accuracy = 77.55 |best_accuracy = 79.39\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "num_epochs =15\n",
    "steps_per_epoch = len(train_dataloader)\n",
    "\n",
    "def run_per_model(model,lr=2e-3,gamma=0.5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler =  torch.optim.lr_scheduler.StepLR(optimizer, step_size=steps_per_epoch, gamma=gamma)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    checkpoint_path = \"checkpoint.pth\"\n",
    "    run(model, train_dataloader, test_dataloader, criterion, optimizer, scheduler, num_epochs, checkpoint_path, verbose=True)\n",
    "\n",
    "\n",
    "run_per_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff06c07dec643458ca2d9e9d8a56ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:  79.3877182006836\n",
      "basic model size:  260638\n",
      "optimized model size:  191773\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "model = MyModel().cuda()\n",
    "# load checkpoint\n",
    "steps_per_epoch = len(train_dataloader)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "scheduler =  torch.optim.lr_scheduler.StepLR(optimizer, step_size=steps_per_epoch, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "load_checkpoint(model, optimizer, scheduler, \"checkpoint.pth\")\n",
    "# check model accuracy\n",
    "acc = evaluate(model, test_dataloader, verbose=True)\n",
    "print(\"Accuracy of the model: \", acc)\n",
    "\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "example = torch.rand(1, 80, 6).cuda()\n",
    "\n",
    "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "traced_script_module = torch.jit.trace(model, example)\n",
    "# save\n",
    "traced_script_module.save(\"model.pt\")\n",
    "\n",
    "optimized_torchscript_model = optimize_for_mobile(traced_script_module)\n",
    "\n",
    "# Save the TorchScript model\n",
    "optimized_torchscript_model._save_for_lite_interpreter(\"optimized_model.ptl\")\n",
    "\n",
    "\n",
    "# compare model size\n",
    "\n",
    "basic_model_size = os.path.getsize(\"model.pt\")\n",
    "print(\"basic model size: \", basic_model_size)\n",
    "optimized_model_size = os.path.getsize(\"optimized_model.pt\")\n",
    "print(\"optimized model size: \", optimized_model_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
